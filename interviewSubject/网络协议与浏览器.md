## 网络协议

### 1、TCP/IP四层与OSI七层网络模型

![太厉害了，终于有人能把TCP/IP 协议讲的明明白白了](https://s2.51cto.com/oss/201906/17/f58f6ad856c6802b636d20d8f5ba2c3e.jpeg)

#### TCP与UDP

- TCP 是面向连接的、**可靠**的流协议。流就是指不间断的数据结构，当应用程序采用 TCP 发送消息时，虽然可以保证发送的顺序，但还是犹如没有任何间隔的数据流发送给接收端。TCP 为提供可靠性传输，实行“**顺序控制**”或“**重发控制**”机制。此外还具备“流控制（流量控制）”、“拥塞控制”、提高网络利用率等众多功能。
- UDP 是**不具有可靠性**的数据报协议。细微的处理它会交给上层的应用去完成。在 UDP 的情况下，虽然可以确保发送消息的大小，却不能保证消息一定会到达。因此，应用有时会根据自己的需要进行重发处理。
- TCP 和 UDP 的优缺点无法简单地、绝对地去做比较：TCP 用于在传输层有必要实现可靠传输的情况；而在一方面，UDP 主要用于那些对高速传输和实时性有较高要求的通信或广播通信。TCP 和 UDP 应该根据应用的目的按需使用。

#### TCP数据报结构

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200319132644853.png)

- ​	序号：Seq（Sequence Number）序号占32位，用来标识从计算机A发送到计算机B的数据包的序号，计算机发送数据时对此进行标记。

- ​	确认号：Ack（Acknowledge Number）确认号占32位，客户端和服务器端都可以发送，Ack = Seq + 1。

- ​	标志位：每个标志位占用1Bit，共有6个，分别为 URG、ACK、PSH、RST、SYN、FIN，具体含义如下：

  ​		URG：紧急指针（urgent pointer）有效。
  ​		ACK：确认序号有效。
  ​		PSH：接收方应该尽快将这个报文交给应用层。
  ​		RST：重置连接。
  ​		SYN：建立一个新连接。
  ​		FIN：断开一个连接。

#### TCP三次握手、四次挥手

三次握手：

1. 首先 Client 端发送连接请求报文
2. Server 段接受连接后回复 ACK 报文，并为这次连接分配资源。
3. Client 端接收到 ACK 报文后也向 Server 段发生 ACK 报文，并分配资源，这样 TCP 连接就建立了。

![太厉害了，终于有人能把TCP/IP 协议讲的明明白白了](https://s3.51cto.com/oss/201906/17/7b09f56589ba71b99fad5aeae19f363d.jpeg)

##### 为什么需要三次握手：

​	1、在第一次通信过程中，A向B发送信息之后，B收到信息后可以确认自己的收信能力和A的发信能力没有问题。

​	2、在第二次通信中，B向A发送信息之后，A可以确认自己的发信能力和B的收信能力没有问题，但是B不知道自己的发信能力到底如何，所以就需要第三次通信。

​	3、在第三次通信中，A向B发送信息之后，B就可以确认自己的发信能力没有问题。

​	4、 小结：3次握手完成两个重要的功能，既要双方做好发送数据的准备工作(双方都知道彼此已准备好)，也要允许双方就初始序列号进行协商，这个序列号在握手过程中被发送和确认

四次挥手：

1. 服务端申请断开连接即FIN，发送Seq+Ack
2. 客户端接收信息返回，表示我已经接收到
3. 客户端发送信息表示可以断开连接
4. 服务端接受信息，返回数据表示已接受信息

![太厉害了，终于有人能把TCP/IP 协议讲的明明白白了](https://s4.51cto.com/oss/201906/17/f0adfc32f118133170ad1a48b5a2eb58.jpeg)

##### 连接三次，关闭却是四次：

- 因为当Server端收到Client端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中ACK报文是用来应答的，SYN报文是用来同步的。
- 但是关闭连接时，当Server端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉Client端，“你发的FIN报文我收到了”。
- 只有等到我Server端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四步握手。

### 2、http1.x、SPDY和http2.x

#### HTTP1.X缺陷：

1. 高延迟 — 队头阻塞(Head-Of-Line Blocking)

   ​	队头阻塞是指当顺序发送的请求序列中的一个请求因为某种原因被阻塞时，在后面排队的所有请求也一并被阻塞，会导致客户端迟迟收不到数据。

   针对队头阻塞：

   ​		将同一页面的资源分散到不同域名下，提升连接上限。虽然能公用一个 TCP 管道，但是在一个管道中同一时刻只能处理一个请求，在当前的请求没有结束之前，其他的请求只能处于阻塞状态。

   ​		减少请求数量

   ​		内联一些资源：css、base64 图片等

   ​		合并小文件减少资源数

2. 无状态特性 — 阻碍交互

   ​		无状态是指协议对于连接状态没有**记忆能力**。纯净的 HTTP 是没有 cookie 等机制的，每一个连接都是一个新的连接。上一次请求验证了用户名密码，而下一次请求服务器并不知道它与上一条请求有何关联，换句话说就是**掉登录态**。

3. 明文传输 — 不安全性

   ​		传输内容没有加密，中途可能被篡改和劫持。

4. 不支持服务端推送

#### SPDY特性：

google 推行的改进版本的 HTTP1.1

1. 多路复用 — 解决队头阻塞

   ​		SPDY 允许在一个连接上无限制并发流。因为请求在一个通道上，TCP 效率更高（参考 [TCP 拥塞控制](https://zhuanlan.zhihu.com/p/37379780) 中的**慢启动**）。更少的网络连接，发出更密集的包。

2. 头部压缩 — 解决巨大的 HTTP 头部

   ​		使用专门的 HPACK 算法，每次请求和响应只发送差异头部，一般可以达到 50%~90% 的高压缩率。

3. 请求优先级 — 先获取重要数据

   ​		虽然无限的并发流解决了队头阻塞的问题，但如果带宽受限，客户端可能会因防止堵塞通道而阻止请求。在网络通道被非关键资源堵塞时，高优先级的请求会被优先处理。

4. 服务端推送 — 填补空缺

   ​		[服务端推送（ServerPush）](https://link.zhihu.com/?target=http%3A//www.ruanyifeng.com/blog/2018/03/http2_server_push.html)，可以让服务端主动把资源文件推送给客户端。当然客户端也有权利选择是否接收。

5. 提高安全性

   ​		支持使用 HTTPS 进行加密传输。

#### HTTP2

HTTP2 基于 SPDY，专注于性能，最大的一个目标是在用户和网站间只用一个连接。

1. 二进制分帧 - HTTP2 性能增强的核心

   ​		首先，HTTP2 没有改变 HTTP1 的语义，只是在应用层使用二进制分帧方式传输。因此，也引入了新的通信单位：**帧、消息、流**。

   ​		分帧有什么好处？服务器单位时间接收到的请求数变多，可以提高并发数。最重要的是，为多路复用提供了底层支持。

2. 多路复用 - 解决串行的文件传输和连接数过多

   ​		一个域名对应一个连接，一个流代表了一个完整的**请求-响应**过程。**帧**是最小的数据单位，每个**帧**会标识出该帧属于哪个**流**，**流**也就是多个帧组成的数据流。多路复用，就是在一个 TCP 连接中可以存在多个流。

#### HTTP2 的缺陷

1. TCP 以及 TCP+TLS 建立连接的延时

   ​	TCP 连接需要和服务器进行**三次握手**，即消耗完 1.5 个 RTT 之后才能进行数据传输。

   ​	TLS 连接有两个版本—— TLS1.2 和 TLS1.3，每个版本建立连接所花的时间不同，大致需要 1~2 个 RTT。

   ​	RTT（Round-Trip Time）:
   ​		**往返时延**。表示从发送端发送数据开始，到发送端收到来自接收端的确认（接收端收到数据后便立即发送确认），总共经历的时延。

2. TCP 的队头阻塞并没有彻底解决

   ​		TCP 为了保证可靠传输，有一个“超时重传”机制，丢失的包必须等待重传确认。HTTP2 出现丢包时，整个 TCP 都要等待重传，那么就会阻塞该 TCP 连接中的所有请求。

3. 多路复用导致服务器压力上升

   ​		多路复用没有限制同时请求数。请求的平均数量与往常相同，但实际会有许多请求的短暂爆发，导致瞬时 QPS 暴增。

4. 多路复用容易 Timeout

   ​		大批量的请求同时发送，由于 HTTP2 连接内存在多个并行的流，而网络带宽和服务器资源有限，每个流的资源会被稀释，虽然它们开始时间相差更短，但却都可能超时。

   ​		即使是使用 Nginx 这样的负载均衡器，想正确进行节流也可能很棘手。 其次，就算你向应用程序引入或调整排队机制，但一次能处理的连接也是有限的。如果对请求进行排队，还要注意在响应超时后丢弃请求，以避免浪费不必要的资源。

#### QUIC

​	Google在推 SPDY 的时候就已经意识到了这些问题，于是就另起炉灶搞了一个基于 UDP 协议的 QUIC 协议。而这个就是 HTTP3。它真正“完美”地解决了“队头阻塞”问题。

1. 改进的拥塞控制、可靠传输
2. 快速握手
3. 集成了 TLS 1.3 加密
4. 多路复用
5. 连接迁移

### 3、http和https协议

#### http

​	http超文本传输协议(Hyper Text Transfer Protocol)，基于TCP/IP通信协议，一般用于B/S架构。

#### http特点

1. http协议支持客户端/服务端模式，也是一种请求/响应模式的协议。
2. 简单快速：客户向服务器请求服务时，只需传送请求方法和路径。请求方法常用的有GET、HEAD、POST。
3. 灵活：HTTP允许传输任意类型的数据对象。传输的类型由Content-Type加以标记。
4. 无连接：限制每次连接只处理一个请求。服务器处理完请求，并收到客户的应答后，即断开连接，但是却不利于客户端与服务器保持会话连接，为了弥补这种不足，产生了两项记录http状态的技术，一个叫做Cookie,一个叫做Session。
5. 无状态：无状态是指协议对于事务处理没有记忆，后续处理需要前面的信息，则必须重传。

#### http报文

​	请求报文：

- 请求行：包括请求方法、URL、协议/版本
- 请求头(Request Header)
- 请求正文

​	响应报文：

- 状态行：请求状态
- 响应头(Response Header)
- 响应正文

#### 常见请求方法

- GET: 请求指定的页面信息，并返回实体主体。
- POST: 向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。POST请求可能会导致新的资源的建立和/或已有资源的修改。
- HEAD: 类似于get请求，只不过返回的响应中没有具体的内容，用于获取报头
- PUT: 从客户端向服务器传送的数据取代指定的文档的内容。
- DELETE: 请求服务器删除指定的页面。

#### GET和POST的区别

- 都包含请求头请求行，post多了请求body。
- get多用来查询，请求参数放在url中，不会对服务器上的内容产生作用。post用来提交，如把账号密码放入body中。
- GET是直接添加到URL后面的，直接就可以在URL中看到内容，而POST是放在报文内部的，用户无法直接看到。
- GET提交的数据长度是有限制的，因为URL长度有限制，具体的长度限制视浏览器而定。而POST没有。

#### 响应状态码

分类：

- 1XX- 信息型，服务器收到请求，需要请求者继续操作。
- 2XX- 成功型，请求成功收到，理解并处理。
- 3XX - 重定向，需要进一步的操作以完成请求。
- 4XX - 客户端错误，请求包含语法错误或无法完成请求。
- 5XX - 服务器错误，服务器在处理请求的过程中发生了错误

常见状态码：

- 200 OK - 客户端请求成功
- 301 - 资源（网页等）被永久转移到其它URL
- 302 - 临时跳转
- 304 - 协商缓存
- 400 Bad Request - 客户端请求有语法错误，不能被服务器所理解
- 401 Unauthorized - 请求未经授权，这个状态代码必须和WWW-Authenticate报头域一起使用
- 404 - 请求资源不存在，可能是输入了错误的URL
- 500 - 服务器内部发生了不可预期的错误
- 503 Server Unavailable - 服务器当前不能处理客户端的请求，一段时间后可能恢复正常。

#### https

​	https协议(HyperText Transfer Protocol over Secure Socket Layer)，一般理解为HTTP+SSL/TLS，通过 SSL证书来验证服务器的身份，并为浏览器和服务器之间的通信进行加密。

​	SSL（Secure Socket Layer，安全套接字层）：1994年为 Netscape 所研发，SSL 协议位于 TCP/IP 协议与各种应用层协议之间，为数据通讯提供安全支持。

​	TLS（Transport Layer Security，传输层安全）：其前身是 SSL，它最初的几个版本（SSL 1.0、SSL 2.0、SSL 3.0）由网景公司开发，1999年从 3.1 开始被 IETF 标准化并改名，发展至今已经有 TLS 1.0、TLS 1.1、TLS 1.2 三个版本。SSL3.0和TLS1.0由于存在安全漏洞，已经很少被使用到。TLS 1.3 改动会比较大，目前还在草案阶段，目前使用最广泛的是TLS 1.1、TLS 1.2。

#### http存在问题

- 请求信息明文传输，容易被窃听截取。
- 数据的完整性未校验，容易被篡改
- 没有验证对方身份，存在冒充危险

#### https传输流程

使用非对称加密 去加密 对称加密的密钥，通过对称加密进行密文通信。

![preview](https://pic4.zhimg.com/v2-a994fbf3094d737814fe01c2b919477b_r.jpg)

1. 首先客户端通过URL访问服务器建立SSL连接。
2. 服务端收到客户端请求后，会将网站支持的证书信息（证书中包含公钥）传送一份给客户端。
3. 客户端的服务器开始协商SSL连接的安全等级，也就是信息加密的等级。
4. 客户端的浏览器根据双方同意的安全等级，建立会话密钥，然后利用网站的公钥将会话密钥加密，并传送给网站。
5. 服务器利用自己的私钥解密出会话密钥。
6. 服务器利用会话密钥加密与客户端之间的通信

#### 对称加密和非对称加密

对称加密：加密和解密使用的是同一把钥匙。

​	优点：算法简单，加密解密容易，效率高，执行快。

​	缺点：相对来说不算特别安全，只有一把钥匙，密文如果被拦截，且密钥也被劫持，那么，信息很容易被破译。

非对称加密： 使用不同的密钥进行加密和解密，公钥（Public Key）和私钥（Private Key）。公钥和私钥是成对的存在，如果对原文使用公钥加密，则只能使用对						应的私钥才能解密。

​	优点：安全，即使密文被拦截、公钥被获取，但是无法获取到私钥，也就无法破译密文。作为接收方，务必要保管好自己的密钥。

​	缺点：加密算法及其复杂，安全性依赖算法与密钥，而且加密和解密效率很低。

#### 数字证书和数字签名

数字证书：由权威机构Certificate Authority发行的，又称之为证书授权，简称为：CA。类似于现实生活中的居民身份证，绑定了公钥及其持有者的真实身份，是一段含有证书持有者身份信息并经过认证中心审核签发的电子数据。

数字签名：指将摘要信息使用接收者的公钥进行加密，与密文一起发送给接收者。接收者使用自己的私钥对摘要信息进行解密，然后使用Hash函数对收到的密文产生一个摘要信息，然后将摘要信息与发送着传输过来解密后的摘要信息对比是否一致。如果一致，则表明数据信息没有被篡改。

数字签名能够验证收到的信息的完整性，避免中途信息被劫持篡改或丢失。对方可以根据数字签名来判断获取到的数据信息时候是最原始的数据。

#### https缺点

- HTTPS协议多次握手，导致页面的加载时间延长近50%；
- HTTPS连接缓存不如HTTP高效，会增加数据开销和功耗；
- 申请SSL证书需要钱，功能越强大的证书费用越高。
- SSL涉及到的安全算法会消耗 CPU 资源，对服务器资源消耗较大。

#### http和https异同

- HTTPS是HTTP协议的安全版本，HTTP协议的数据传输是明文的，是不安全的，HTTPS使用了SSL/TLS协议进行了加密处理。
- http和https使用连接方式不同，默认端口也不一样，http是80，https是443。
- HTTPS协议需要到CA申请证书，一般免费证书很少，需要交费。
- HTTPS可以有效的防止运营商劫持，解决了防劫持的一个大问题。

### 4、网络安全

#### XSS（跨站脚本攻击(Cross Site Scripting)）

反射型(非持久型)：要触发漏洞，需要访问特定的链接才能够实现。(带非法参数访问url， eval()解码)

储存型(持久型)：服务器再接收到我们的恶意脚本时会将其做一些处理。(留言板)

- **劫持访问**，
- **盗用cookie实现无密码登录**
- **配合csrf攻击完成恶意请求**(Csrf攻击(跨站请求伪造)就是在未经你许可的情况下用你的名义发送恶意请求（比如修改密码，银行转账等）)

防御：

​	现在主流的浏览器内置了防范 XSS 的措施，例如 CSP（内容安全策略 Content-Security-Policy ）。但对于开发者来说，也应该寻找可靠的解决方案来防止 XSS 攻击。

​	CSP**通过指定有效域——即浏览器认可的可执行脚本的有效来源**——使服务器管理者有能力减少或消除XSS攻击所依赖的载体。一个CSP兼容的浏览器将会仅执行从白名单域获取到的脚本文件，忽略所有的其他脚本 (包括内联脚本和HTML的事件处理属性)。

Chrome 51 开始，浏览器的 Cookie 新增加了一个**SameSite**属性，用来防止 ***CSRF 攻击*** 和用户追踪（第三方恶意获取cookie），限制第三方 Cookie，从而减少安全风险。

**Strict**：严格，完全禁止第三方获取cookie，跨站点时，任何情况下都不会发送cookie；只有当前网页的 URL 与请求目标一致，才会带上 Cookie。这个规则过于严格，可能造成非常不好的用户体验。比如，当前网页有一个 GitHub 链接，用户点击跳转就不会带有 GitHub 的 Cookie，跳转过去总是未登陆状态。

**Lax**：防范跨站，大多数情况下禁止获取cookie，除非导航到目标网址的GET请求（链接、预加载、GET表单）；设置了`Strict`或`Lax`以后，基本就杜绝了 [CSRF](https://so.csdn.net/so/search?q=CSRF&spm=1001.2101.3001.7020) 攻击。当然，前提是用户浏览器支持 SameSite 属性。**SameSite属性的默认SameSite=Lax**

**None**：没有限制。

**必须同时设置`Secure`属性（Cookie 只能通过 HTTPS 协议发送），否则无效。**





- **HttpOnly** 防止劫取 Cookie，能阻止 XSS 攻击后的 Cookie 劫持攻击。
- **输入检查**，对于用户的任何输入要进行**检查、过滤和转义**。建立可信任的字符和 HTML 标签白名单，对于不在白名单之列的字符或者标签进行**过滤或编码**。一些前端框架中，都会有一份 decodingMap， 用于对用户输入所包含的特殊字符或标签进行编码或过滤，如 <，>，script，防止 XSS 攻击。
- **输出检查**，用户的输入会存在问题，服务端的输出也会存在问题。一般来说，除富文本的输出外，在变量输出到 HTML 页面时，可以使用编码或转义的方式来防御 XSS 攻击。例如利用 sanitize-html 对输出内容进行有规则的过滤之后再输出到页面中。
- 请求令牌 ，改良api设计，对于资源改动的请求**采用post而非get**
- 最后是**限制**。通过以上的案例我们不难发现xss攻击要能达成往往需要较长的字符串，因此对于一些可以预期的输入可以通过**限制长度强制截断**来进行防御。

#### CSRF（跨站请求伪造( Cross Site Request Forgery)）

​		CSRF 攻击是攻击者借助受害者的 Cookie 骗取服务器的信任，可以在受害者毫不知情的情况下以受害者名义伪造请求发送给受攻击服务器，从而在并未授权的情况下执行在权限保护之下的操作。

​		由于 Cookie 中包含了用户的认证信息，当用户访问攻击者准备的攻击环境时，攻击者就可以对服务器发起 CSRF 攻击。在这个攻击过程中，**攻击者借助受害者的 Cookie 骗取服务器的信任，但并不能拿到 Cookie，也看不到 Cookie 的内容。**而对于服务器返回的结果，由于浏览器同源策略的限制，攻击者也无法进行解析。因此，攻击者无法从返回的结果中得到任何东西，他所能做的就是给服务器发送请求，以执行请求中所描述的命令，在服务器端直接改变数据的值，而非窃取服务器中的数据。

但若 CSRF 攻击的目标并不需要使用 Cookie，则也不必顾虑浏览器的 Cookie 策略了。

防范：

- **验证码**

  ​        验证码被认为是对抗 CSRF 攻击最简洁而有效的防御方法。

  ​        从上述示例中可以看出，CSRF 攻击往往是在用户不知情的情况下构造了网络请求。而验证码会强制用户必须与应用进行交互，才能完成最终请求。因为通常情况下，验证码能够很好地遏制 CSRF 攻击。

  ​        但验证码并不是万能的，因为出于用户考虑，不能给网站所有的操作都加上验证码。因此，验证码只能作为防御 CSRF 的一种辅助手段，而不能作为最主要的解决方案。

- **Referer Check**

  ​		根据 HTTP 协议，在 HTTP 头中有一个字段叫 Referer，它记录了该 HTTP 请求的来源地址。通过 Referer Check，可以检查请求是否来自合法的”源”。

  比如，如果用户要删除自己的帖子，那么先要登录 www.c.com，然后找到对应的页面，发起删除帖子的请求。此时，Referer 的值是 http://www.c.com；当请求是从 www.a.com 发起时，Referer 的值是 http://www.a.com 了。因此，要防御 CSRF 攻击，只需要对于每一个删帖请求验证其 Referer 值，如果是以 www.c.com 开头的域名，则说明该请求是来自网站自己的请求，是合法的。如果 Referer 是其他网站的话，则有可能是 CSRF 攻击，可以拒绝该请求。

  ​        Referer Check 不仅能防范 CSRF 攻击，另一个应用场景是 “防止图片盗链”。

- **添加 token 验证(token==令牌)**

  ​        CSRF 攻击之所以能够成功，是因为攻击者可以完全伪造用户的请求，该请求中所有的用户验证信息都是存在于 Cookie 中，因此攻击者可以在不知道这些验证信息的情况下直接利用用户自己的 Cookie 来通过安全验证。要抵御 CSRF，关键在于在请求中放入攻击者所不能伪造的信息，并且该信息不存在于 Cookie 之中。可以在 HTTP 请求中以参数的形式加入一个随机产生的 token，并在服务器端建立一个拦截器来验证这个 token，如果请求中没有 token 或者 token 内容不正确，则认为可能是 CSRF 攻击而拒绝该请求。

### 5、http缓存

![img](https://upload-images.jianshu.io/upload_images/4845448-39248bf4a3b45c3e?imageMogr2/auto-orient/strip|imageView2/2/format/webp)



​	**常见的http缓存只能缓存get请求响应的资源，对于其他类型的响应则无能为力**

#### 缓存位置

![clipboard.png](https://segmentfault.com/img/bVbwrBF?w=782&h=356)

从缓存位置上来看，分为4种，从上往下依次检查是否命中，如果都没有命中则重新发起请求。
**Service Worker** 是运行在浏览器背后的独立线程，一般可以用来实现缓存功能。使用 Service Worker的话，传输协议必须为 HTTPS。
**Memory Cache** 也就是内存中的缓存，主要包含的是当前中页面中已经抓取到的资源,例如页面上已经下载的样式、脚本、图片等。读取内存中的数据肯定比磁盘快,内存缓存虽然读取高效，可是缓存持续性很短，会随着进程的释放而释放。 一旦我们关闭 Tab 页面，内存中的缓存也就被释放了。
内存缓存中有一块重要的缓存资源是preloader相关指令（例如<link rel="prefetch">）下载的资源。它可以一边解析js/css文件，一边网络请求下一个资源。
**Disk Cache** 也就是存储在硬盘中的缓存，读取速度慢点，但是什么都能存储到磁盘中，比之 Memory Cache 胜在容量和存储时效性上。
绝大部分的缓存都来自Disk Cache，在HTTP 的协议头中设置。
**Push Cache**（推送缓存）是 HTTP/2 中的内容，当以上三种缓存都没有命中时，它才会被使用。它只在会话（Session）中存在，一旦会话结束就被释放，并且缓存时间也很短暂，在Chrome浏览器中只有5分钟左右，同时它也并非严格执行HTTP头中的缓存指令。

#### http缓存分类

​	根据是否需要重新向服务器发起请求来分类，可分为(强制缓存，协商缓存) 。

​	根据是否可以被单个或者多个用户使用来分类，可分为(私有缓存，共享缓存) 

​	强制缓存如果生效，不需要再和服务器发生交互，而协商缓存不管是否生效，都需要与服务端发生交互。

![img](https://upload-images.jianshu.io/upload_images/4845448-ab0e961921da5694?imageMogr2/auto-orient/strip|imageView2/2/format/webp)

#### 强缓存

​	强制缓存在缓存数据未失效的情况下（即Cache-Control的max-age没有过期或者Expires的缓存时间没有过期），那么就会直接使用浏览器的缓存数据，不会再向服务器发送任何请求。强制缓存生效时，http状态码为200。

![img](https://upload-images.jianshu.io/upload_images/4845448-217723260f75ed90?imageMogr2/auto-orient/strip|imageView2/2/format/webp) 	

在chrome浏览器中返回的200状态会有两种情况：
 1、from memory cache
 (从内存中获取/一般缓存更新频率较高的js、图片、字体等资源)

2、from disk cache
 (从磁盘中获取/一般缓存更新频率较低的js、css等资源)

这两种情况是chrome自身的一种缓存策略，这也是为什么chrome浏览器响应的快的原因。其他浏览返回的是已缓存状态，没有标识是从哪获取的缓存。

#### 协商缓存

​		当第一次请求时服务器返回的响应头中没有Cache-Control和Expires或者Cache-Control和Expires过期还或者它的属性设置为no-cache时(即不走强缓存)，那么浏览器第二次请求时就会与服务器进行协商，与服务器端对比判断资源是否进行了修改更新。

​		如果服务器端的资源没有修改，那么就会返回**304状态码**，告诉浏览器可以使用缓存中的数据，这样就减少了服务器的数据传输压力。如果数据有更新就会返回**200状态码**，服务器就会返回更新后的资源并且将缓存信息一起返回。

​		跟协商缓存相关的header头属性有（ETag/If-Not-Match 、Last-Modified/If-Modified-Since），**请求头和响应头需要成对出现**

![img](https://upload-images.jianshu.io/upload_images/4845448-a22cef109d00aa79?imageMogr2/auto-orient/strip|imageView2/2/w/800/format/webp)

​		协商缓存的执行流程是这样的：当浏览器第一次向服务器发送请求时，会在响应头中返回协商缓存的头属性：ETag和Last-Modified,其中ETag返回的是一个hash值，Last-Modified返回的是GMT格式的最后修改时间。然后浏览器在第二次发送请求的时候，会在请求头中带上与ETag对应的If-Not-Match，其值就是响应头中返回的ETag的值，Last-Modified对应的If-Modified-Since。服务器在接收到这两个参数后会做比较，如果返回的是304状态码，则说明请求的资源没有修改，浏览器可以直接在缓存中取数据，否则，服务器会直接返回数据。

**注意：**
 ETag/If-Not-Match是在HTTP/1.1出现的，主要是解决以下问题：

(1)、Last-Modified标注的最后修改只能精确到秒级，如果某些文件在1秒钟以内，被修改多次的话，它将不能准确标注文件的修改时间

(2)、如果某些文件被修改了，但是内容并没有任何变化，而Last-Modified却改变了，导致文件没法使用缓存

(3)、有可能存在服务器没有准确获取文件修改时间，或者与代理服务器时间不一致等情形

#### 浏览器首次和再次发送http请求的执行流程图

![img](https://upload-images.jianshu.io/upload_images/4845448-4b270d197649b733?imageMogr2/auto-orient/strip|imageView2/2/format/webp)

![img](https://upload-images.jianshu.io/upload_images/4845448-d2cac3511e372486?imageMogr2/auto-orient/strip|imageView2/2/format/webp)



#### 私有缓存和共享缓存

私有缓存只能用于单独的用户：Cache-Control: Private（浏览器级缓存）

共享缓存可以被多个用户使用: Cache-Control: Public （代理级缓存）

#### http缓存好处

- 减少了冗余的数据传输，节省了网费。
- 缓解了服务器的压力， 大大提高了网站的性能
- 加快了客户端加载网页的速度

#### 如何使用http缓存

​	一般需要缓存的资源有html页面和其他静态资源

​	1、html页面缓存的设置主要是在<head>标签中嵌入<meta>标签，这种方式只对页面有效，对页面上的资源无效

​		1.1、html页面禁用缓存的设置如下：

```javascript
// 仅有IE浏览器才识别的标签，不一定会在请求字段加上Pragma，但的确会让当前页面每次都发新请求
<meta http-equiv="pragma" content="no-cache">
// 仅有IE浏览器才识别的标签，该方式仅仅作为知会IE缓存时间的标记，你并不能在请求或响应报文中找到Expires字段    
<meta http-equiv="expires" content="0">
// 其他主流浏览器识别的标签
<meta http-equiv="cache-control" content="no-cache">
```

​		1.2、html设置缓存如下：

```javascript
// 仅有IE浏览器才识别的标签
<meta http-equiv="Expires" content="Mon, 20 Aug 2018 23:00:00 GMT" />
// 其他主流浏览器识别的标签
<meta http-equiv="Cache-Control" content="max-age=7200" />
```

​	2、静态资源的缓存一般是在web服务器上配置的，常用的web服务器有：nginx、apache。具体的配置这里不做详细介绍，大家自行查阅。

#### HTTP缓存的几个注意点

1、强缓存情况下，只要缓存还没过期，就会直接从缓存中取数据，就算服务器端有数据变化，也不会从服务器端获取了，这样就无法获取到修改后的数据。决解的办法有：在修改后的资源加上随机数,确保不会从缓存中取。

例如：
 [http://www.kimshare.club/kim/common.css?v=22324432](https://links.jianshu.com/go?to=http%3A%2F%2Fwww.kimshare.club%2Fkim%2Fcommon.css%3Fv%3D22324432)
 [http://www.kimshare.club/kim/common.2312331.css](https://links.jianshu.com/go?to=http%3A%2F%2Fwww.kimshare.club%2Fkim%2Fcommon.2312331.css)

2、尽量减少304的请求，因为我们知道，协商缓存每次都会与后台服务器进行交互，所以性能上不是很好。从性能上来看尽量多使用强缓存。

3、与缓存相关的几个header属性有：Vary、Date/Age。

Vary：表示服务端会以什么基准字段来区分、筛选缓存版本。

​		 	在服务端有着这么一个地址，如果是IE用户则返回针对IE开发的内容，否则返回另一个主流浏览器版本的内容。
 			格式：Vary: User-Agent
​	 		知会代理服务器需要以 User-Agent 这个请求首部字段来区别缓存版本，防止传递给客户端的缓存不正确。

Date/Age：区分其收到的资源是否命中了代理服务器的缓存。

​			Date 理所当然是原服务器发送该资源响应报文的时间（GMT格式），如果你发现 Date 的时间与“当前时间”差别较大，或者连续F5刷新发现 Date 的值都没变化，则说明你当前请求是命中了代理服务器的缓存。
 		   Age 也是响应报文中的首部字段，它表示该文件在代理服务器中存在的时间（秒），如文件被修改或替换，Age会重新由0开始累计。

### 6、websocket

它的最大特点就是，服务器可以主动向客户端推送信息，客户端也可以主动向服务器发送信息，是真正的双向平等对话，属于服务器推送技术的一种。

（1）建立在 TCP 协议之上，服务器端的实现比较容易。

（2）与 HTTP 协议有着良好的兼容性。默认端口也是80和443，并且握手阶段采用 HTTP 协议，因此握手时不容易屏蔽，能通过各种 HTTP 代理服务器。

（3）数据格式比较轻量，性能开销小，通信高效。

（4）可以发送文本，也可以发送二进制数据。

（5）没有同源限制，客户端可以与任意服务器通信。

（6）协议标识符是`ws`（如果加密，则为`wss`），服务器网址就是 URL。

#### **WebSocket连接过程**

客户端发起HTTP握手，告诉服务端进行WebSocket协议通讯，并告知WebSocket协议版本。服务端确认协议版本，升级为WebSocket协议。之后如果有数据需要推送，会主动推送给客户端。

连接开始时，客户端使用HTTP协议和服务端升级协议，升级完成后，后续数据交换遵循WebSocket协议。我们看看Request Headers

```javascript
Accept-Encoding: gzip, deflate, br
Accept-Language: zh,zh-TW;q=0.9,en-US;q=0.8,en;q=0.7,zh-CN;q=0.6
Cache-Control: no-cache
Connection: Upgrade
Host: 127.0.0.1:3000
Origin: http://localhost:3000
Pragma: no-cache
Sec-WebSocket-Extensions: permessage-deflate; client_max_window_bits
Sec-WebSocket-Key: bwb9SFiJONXhQ/A4pLaXIg==
Sec-WebSocket-Version: 13
Upgrade: websocket
```

重点字段是这些：

- Connection: Upgrade 表示要升级协议
- Upgrade: websocket 要升级协议到websocket协议
- Sec-WebSocket-Version 表示websocket的版本。如果服务端不支持该版本，需要返回一个Sec-WebSocket-Versionheader，里面包含服务端支持的版本号。
- Sec-WebSocket-Key 对应服务端响应头的Sec-WebSocket-Accept，由于没有同源限制，websocket客户端可任意连接支持websocket的服务。这个就相当于一个钥匙一把锁，避免多余的，无意义的连接。

再看看看服务端响应的 Response Headers

```json
Connection: Upgrade
Sec-WebSocket-Accept: 2jrbCWSCPlzPtxarlGTp4Y8XD20=
Upgrade: websocket
```

关键是这个字段

- Sec-WebSocket-Accept: 用来告知服务器愿意发起一个websocket连接， 值根据客户端请求头的Sec-WebSocket-Key计算出来

#### **WebSocket API**

客户端若想要与支持webScoket的服务器通信，可以使用WebSocket构造函数返回WebSocket对象。

```javascript
const ws = new WebSocket("ws://localhost:3000/websocket");
//服务端nodejs可使用 'ws'包
//引入websocket 的ws模块
var WebSocketServer = require('ws').Server,
 
//初始化websocket对象
wss = new WebSocketServer({ port: 8181 });

```

这样，客户端就会与服务端开始连接。

返回的实例对象的属性：

- WebSocket.onopen： 连接成功后的回调

- WebSocket.onclose： 连接关闭后的回调

- WebSocket.onerror： 连接失败后的回调

- WebSocket.onmessage： 客户端接收到服务端数据的回调

- webSocket.bufferedAmount： 未发送至服务器的二进制字节数

- WebSocket.binaryType： 使用二进制的数据类型连接

- WebSocket.protocol ： 服务器选择的下属协议

- WebSocket.url ： WebSocket 的绝对路径

- WebSocket.readyState： 当前连接状态，对应的四个常量

  ​	WebSocket.CONNECTING: 0

  ​	WebSocket.OPEN: 1

  ​	WebSocket.CLOSING: 2

  ​	WebSocket.CLOSED: 3

方法：

- WebSocket.close() 关闭当前连接
- WebSocket.send(data) 向服务器发送数据

#### websocket扩展知识

​	webSocket扩展，心跳检测，数据加密，身份认证等

### 7、cookie、session、与token

- 简而言之, session 有如用户信息档案表, 里面包含了用户的认证信息和登录状态等信息. 而 cookie 就是用户通行证

- token可以抵抗csrf(跨站请求伪造)，cookie+session不行，token不要存cookie，存localstorage。

  ​	假如用户正在登陆银行网页，同时登陆了攻击者的网页，并且银行网页未对csrf攻击进行防护。攻击者就可以在网页放一个表单，该表单提交src为`http://www.bank.com/api/transfer`，body为`count=1000&to=Tom`。倘若是session+cookie，用户打开网页的时候就已经转给Tom1000元了.**因为form 发起的 POST 请求并不受到浏览器同源策略的限制，因此可以任意地使用其他域的 Cookie 向其他域发送 POST 请求，形成 CSRF 攻击。**在post请求的瞬间，cookie会被浏览器自动添加到请求头中。**但token不同，token是开发者为了防范csrf而特别设计的令牌，浏览器不会自动添加到headers里**，攻击者也无法访问用户的token，所以提交的表单无法通过服务器过滤，也就无法形成攻击。

- session存储于服务器，可以理解为一个状态列表，拥有一个唯一识别符号sessionId，通常存放于cookie中。服务器收到cookie后解析出sessionId，再去session列表中查找，才能找到相应session。依赖cookie

- cookie类似一个令牌，装有sessionId，存储在客户端，浏览器通常会自动添加。

- token也类似一个令牌，无状态，用户信息都被加密到token中，服务器收到token后解密就可知道是哪个用户，解决session的负载均衡问题，需要开发者手动添加。

- jwt(Json Web Token)只是一个跨域认证的方案

#### cookie：

Cookie 是服务器发送到用户浏览器并保存在本地的一小块数据，它会在浏览器下次向同一服务器再发起请求时被携带并发送到服务器上。Cookie 主要用于以下三个方面：

- 会话状态管理（如用户登录状态、购物车、游戏分数或其它需要记录的信息）
- 个性化设置（如用户自定义设置、主题等）
- 个性化设置（如用户自定义设置、主题等）

而浏览器所持有的 Cookie 分为两种：

- Session Cookie(会话期 Cookie)：会话期 Cookie 是最简单的Cookie，它不需要指定过期时间（Expires）或者有效期（Max-Age），它仅在会话期内有效，浏览器关闭之后它会被自动删除。
- Permanent Cookie(持久性 Cookie)：与会话期 Cookie 不同的是，持久性 Cookie 可以指定一个特定的过期时间（Expires）或有效期（Max-Age）。

```javascript
res.setHeader('Set-Cookie', ['mycookie=222', 'test=3333; expires=Sat, 21 Jul 2018 00:00:00 GMT;']);
```

上述代码创建了两个 Cookie：mycookie 和 test，前者属于会话期 Cookie，后者则属于持久性 Cookie。当我们去查看 Cookie 相关的属性时，**不同的浏览器对会话期 Cookie 的 Expires 属性值会不一样**，此外，每个 Cookie 都会有与之关联的域，这个域的范围一般通过 donmain 属性指定。如果 Cookie 的域和页面的域相同，那么我们称这个 Cookie 为**第一方 Cookie**（first-party cookie），如果 Cookie 的域和页面的域不同，则称之为**第三方 Cookie**（third-party cookie）。一个页面包含图片或存放在其他域上的资源（如图片）时，第一方的 Cookie 也只会发送给设置它们的服务器。

#### cookie什么时候可以携带？

### 8、hls与m3u8

HLS(HTTP Live Streaming) 基于HTTP协议的流媒体解决方案

M3U8文件是指UTF-8编码格式的M3U文件。M3U文件是记录了一个索引纯文本文件，打开它时播放软件并不是播放它，而是根据它的索引找到对应的音视频文件的网络地址进行在线播放。

## 浏览器

### 1、浏览器渲染机制

​	**html的加载与css等资源文件的是可以异步的，但js的加载与执行会挂起html渲染进程**

​	**js通常放在页面尾部，即body结束前。**

​	不完整的CSSOMTree是不可以被使用的，如果JS试图在**浏览器还未完成CSSOMTree的下载和构建**时去操作CSS样式，浏览器会**暂停脚本的运行和DOM的构建**，直至浏览器完成了CSSOM的下载和构建。也就是说，**JS脚本的出现会让CSSOM的构建阻塞DOM的构建**。

1．解析HTML文件，创建DOM树，边下载边解析 (**css放头部，js放尾部**--会阻塞dom树的构建，js会操作dom)

2．解析CSS,形成CSS对象模型(CSSDOM)，css也是边下载边解析，不会阻塞dom，但会阻塞页面渲染，link标签会阻塞js运行。CSS被视为阻塞渲染的资源，应放到代码的头部尽快加载。

3．将CSS与DOM合并，构建渲染树（rendering tree)，样式计算，构建布局树，分层树，图块化

4．布局和绘制

#### 浏览器输入url到页面最后呈现 有哪些过程

1. DNS域名解析

   ​	客户端收到你输入的域名地址后，它首先去找本地的hosts文件，检查在该文件中是否有相应的域名、IP对应关系，如果有，则向其IP地址发送请求，如果没有，再去找DNS服务器。

2. 建立TCP连接（三次握手）

3. 发送HTTP请求

4. 服务器处理请求

5. 返回响应结果

6. 关闭TCP连接（四次挥手）

7. 浏览器解析HTML

8. 浏览器布局渲染；

#### 回流与重绘

​	重绘：不改变布局，color等

​	回流： 改变布局

​	优化：js尽量减少对样式的操作，尽量使用css；resize加上防抖；加载图片提前写好宽高。

​				使用className和cssText合并操作，而不是多次直接修改属性

​				使用documentFragment(最小文档对象，不是真实dom树的一部分)或div等元素进行缓存操作

​				不要经常访问会引起浏览器flush队列的属性，如果要访问，就先读取到变量中进行缓存，以后用的时候直接读取变量。

​				考虑你的操作会影响到render tree中的多少节点以及影响的方式，影响越多，花费肯定就越多。

```javascript
// block1是position:absolute 定位的元素，它移动会影响到它父元素下的所有子元素。  
// 因为在它移动过程中，所有子元素需要判断block1的z-index是否在自己的上面，  
// 如果是在自己的上面,则需要重绘,这里不会引起回流  
$("#block1").animate({left:50});  
// block2是相对定位的元素,这个影响的元素与block1一样，但是因为block2非绝对定位  
// 而且改变的是marginLeft属性，所以这里每次改变不但会影响重绘，  
// 还会引起父元素及其下元素的回流  
$("#block2").animate({marginLeft:50}); 
```

#### defer与async(延迟执行与异步执行)

![preview](https://segmentfault.com/img/bVWhRl?w=801&h=814/view)

```html
<script src="script.js"></script>
没有 defer 或 async，浏览器会立即加载并执行指定的脚本，“立即”指的是在渲染该 script 标签之下的文档元素之前，也就是说不等待后续载入的文档元素，读到就加载并执行。

<script async src="script.js"></script>
有 async，加载和渲染后续文档元素的过程将和 script.js 的加载与执行并行进行（异步）。

<script defer src="myscript.js"></script>
有 defer，加载后续文档元素的过程将和 script.js 的加载并行进行（异步），但是 script.js 的执行要在所有元素解析完成之后，DOMContentLoaded 事件触发之前完成。
```

​	有 `defer`，加载后续文档元素的过程将和 `script.js` 的**加载**并行进行（异步），但是 `script.js` 的**执行**要在所有元素解析完成之后，`DOMContentLoaded` 事件触发之前完成。

​	有 `async`，加载和渲染后续文档元素的过程将和 `script.js` 的**加载与执行**并行进行（异步）。

​	如果项目中脚本之间存在依赖关系，不推荐使用`async`。 

- *defer* 和 *async* 在网络读取（下载）这块儿是一样的，都是异步的（相较于 HTML 解析）
- 它俩的差别在于脚本下载完之后何时执行，显然 *defer* 是最接近我们对于应用脚本加载和执行的要求的
- 关于 *defer*，此图未尽之处在于它是按照加载顺序执行脚本的，这一点要善加利用
- *async* 则是一个乱序执行的主，反正对它来说脚本的加载和执行是紧紧挨着的，所以不管你声明的顺序如何，只要它加载完了就会立刻执行
- 仔细想想，*async* 对于应用脚本的用处不大，因为它完全不考虑依赖（哪怕是最低级的顺序执行），不过它对于那些可以不依赖任何脚本或不被任何脚本依赖的脚本来说却是非常合适的，最典型的例子：Google Analytics

### 2、垃圾回收

#### 垃圾回收算法

1. 标记空间中「可达」值。
   	V8 采用的是**可达性 (reachability) 算法**来判断堆中的对象应不应该被回收。这个算法的思路是这样的：
   		从根节点（Root）出发，遍历所有的对象。
   		可以遍历到的对象，是可达的（reachable）。
   		没有被遍历到的对象，不可达的（unreachable）。
   		在浏览器环境下，根节点有很多，主要包括这几种：

   ​			**全局变量 window，位于每个 iframe 中**

   ​			**文档 DOM 树**

   ​			**存放在栈上的变量**

   ​			...

   ​		这些根节点不是垃圾，不可能被回收。

2. 回收「不可达」的值所占据的内存。
   在所有的标记完成之后，统一清理内存中所有不可达的对象。

3. 做内存整理。
   在频繁回收对象后，内存中就会存在大量不连续空间，专业名词叫「内存碎片」。
   当内存中出现了大量的内存碎片，如果需要分配较大的连续内存时，就有可能出现内存不足的情况。

#### 垃圾回收时机

​	浏览器进行垃圾回收的时候，会暂停 JavaScript 脚本，等垃圾回收完毕再继续执行。

​	**一句话总结分代回收就是：将堆分为新生代与老生代，多回收新生代，少回收老生代。这样就减少了每次需遍历的对象，从而减少每次垃圾回收的耗时。**

**分代收集**
浏览器将数据分为两种，一种是「临时」对象，一种是「长久」对象。
临时对象：
	大部分对象在内存中存活的时间很短；
	比如函数内部声明的变量，或者块级作用域中的变量。当函数或者代码块执行结束时，作用域中定义的变量就会被销毁；
	这类对象很快就变得不可访问，应该快点回收。
长久对象：
	生命周期很长的对象，比如全局的 window、DOM、Web API 等等；
	这类对象可以慢点回收。
这两种对象对应不同的回收策略，所以，V8 把堆分为**新生代和老生代**两个区域， 新生代中存放临时对象，老生代中存放持久对象。
并且让副垃圾回收器、主垃圾回收器，分别负责新生代、老生代的垃圾回收。这样就可以实现高效的垃圾回收啦。
**主垃圾回收器**
	负责老生代的垃圾回收，有两个特点：**对象占用空间大；对象存活时间长**。它使用**「标记-清除」**的算法执行垃圾回收。

​	首先是标记。从一组根元素开始，递归遍历这组根元素；在这个遍历过程中，能到达的元素称为活动对象，没有到达的元素就可以判断为垃圾数据。

​	然后是垃圾清除。直接将标记为垃圾的数据清理掉。多次标记-清除后，**会产生大量不连续的内存碎片，需要进行内存整理。**
**副垃圾回收器**
​	负责新生代的垃圾回收，通常只支持 1~8 M 的容量。新生代被分为两个区域：一半是**对象区域**，一半是**空闲区域。**
​	新加入的对象都被放入对象区域，等对象区域快满的时候，会执行一次垃圾清理。先给对象区域所有垃圾做标记；标记完成后，存活的对象被复制到空闲区域，并且将他们有序的排列一遍；（**复制-收集算法**）
​	这就回到我们前面留下的问题 -- **副垃圾回收器没有碎片整理**。因为空闲区域里此时是有序的，没有碎片，也就不需要整理了；复制完成后，对象区域会和空闲区域进行对调。将空闲区域中存活的对象放入对象区域里。这样，就完成了垃圾回收。因为副垃圾回收器操作比较频繁，所以为了执行效率，一般新生区的空间会被设置得比较小。一旦检测到空间装满了，就执行垃圾回收。

#### 浏览器变量释放

Javascritp 中类型：值类型，引用类型。
引用类型：
	在没有引用之后，通过 V8 自动回收。
值类型：
	如果处于闭包的情况下，要等闭包没有引用才会被 V8 回收；
	非闭包的情况下，等待 V8 的**新生代切换**的时候回收。

### 3、浏览器缓存

#### cookie：

一般由服务器生成，可设置失效时间。如果在浏览器端生成Cookie，默认是关闭浏览器后失效，4KB左右， http-only防止xss攻击。

​	cookie的用法很简单,可以通过服务端设置，js也可以通过documnet.cookie="名称=值;"（不要忘记以;分割）来设置。
​	cookie的**值**字符串可以用encodeURIComponent()来保证它不包含任何逗号、分号或空格(cookie值中禁止使用这些值).
​	cookie一般用做为登陆态保存、密码、个人信息等关键信息保存使用，所以为了安全也是**遵守同源策略原则**的。
​	可以通过下面参数具体设置：
​		;**path**=path (例如 '/', '/mydir') 如果没有定义，默认为当前文档位置的路径。
​		;**domain**=domain (例如 'example.com'， 'subdomain.example.com') 如果没有定义，默认为当前文档位置的路径的域名部分。与早期规范相反的是，在域名前面加 . 符将会被忽视，因为浏览器也许会拒绝设置这样的cookie。如果指定了一个域，那么子域也包含在内。
​		;**max-age=**max-age-in-seconds (例如一年为60*60*24*365)
​		;**expires**=date-in-GMTString-format 如果没有定义，cookie会在对话结束时过期这个值的格式参见Date.toUTCString()
​		;**secure** (cookie只通过https协议传输)
​		;**HttpOnly** 限制web页面程序的browser端script程序读取cookie

```javascript
res.setHeader('Set-Cookie', ['mycookie=222', 'test=3333; expires=Sat, 21 Jul 2018 00:00:00 GMT;']);
```

![img](https://upload-images.jianshu.io/upload_images/4845448-f0cd7f084e812844?imageMogr2/auto-orient/strip|imageView2/2/w/674/format/webp)

cookie、localStorage和sessionSorage仅在客户端（即浏览器）中保存，不参与和服务器的通信。也是**遵守同源策略原则**的。

#### **Web SQL**：

​		WebSQL是前端的一个独立模块，是web存储方式的一种，我们调试的时候会经常看到，只是一般很少使用。并且，当前只有谷歌支持，ie和火狐均不支持。主要方法：

- ​	openDatabase：这个方法使用现有的数据库或者新建的数据库创建一个数据库对象。
- ​	transaction：这个方法让我们能够控制一个事务，以及基于这种情况执行提交或者回滚。
- ​	executeSql：这个方法用于执行实际的 SQL 查询。

#### **indexDB**：

​		IndexedDB 就是浏览器提供的本地数据库，它可以被网页脚本创建和操作。IndexedDB 允许储存大量数据，提供查找接口，还能建立索引。这些都是 LocalStorage 所不具备的。就数据库类型而言，IndexedDB 不属于关系型数据库（不支持 SQL 查询语句），更接近 NoSQL 数据库。